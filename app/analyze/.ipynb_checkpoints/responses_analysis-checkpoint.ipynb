{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Respalizer (c). Data analysis.\n",
    "## Made by Ilya Zakharkin (github.com/izaharkin)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit of natural language processing (sentiment analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data: Given data - responses of people on different bank companies (two features - sentiment (text, in russian) and mark (integer, 1 <= mark <= 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: We must predict which mark will this person give consider his response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful materials:\n",
    "- scikit-learn example: http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#sphx-glr-auto-examples-text-document-classification-20newsgroups-py\n",
    "- TJ texts classification: https://habrahabr.ru/post/327072/\n",
    "- MIPT NLP course: https://github.com/canorbal/NLP_MIPT/blob/master/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import different utilities and tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let`s have a look at the data - how much data do we have, and in what format is it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/responses_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28916"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mark</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Я имею кредитную карту. Пользуюсь ею длительно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Всем привет! Я в этом банке , как только рухну...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Добрый вечер.Был вашим вкладчиком на протяжени...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Очень разочарована банком ВТБ24. За смс уведом...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Отвратительный банк, и обслуживание. 24.11.201...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mark                                        description\n",
       "0     5  Я имею кредитную карту. Пользуюсь ею длительно...\n",
       "1     5  Всем привет! Я в этом банке , как только рухну...\n",
       "2     1  Добрый вечер.Был вашим вкладчиком на протяжени...\n",
       "3     1  Очень разочарована банком ВТБ24. За смс уведом...\n",
       "4     1  Отвратительный банк, и обслуживание. 24.11.201..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let`s change 'description' to 'sentiment':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_columns = data.columns.values\n",
    "new_columns[1] = 'sentiment'\n",
    "data.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28916.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.081685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.591598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mark\n",
       "count  28916.000000\n",
       "mean       2.081685\n",
       "std        1.591598\n",
       "min        1.000000\n",
       "25%        1.000000\n",
       "50%        1.000000\n",
       "75%        3.000000\n",
       "max        5.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are 29k responses, no blank fields, so it is data without holes in it, sentiments are in russian language, marks are from 1 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17651\n",
       "5     5749\n",
       "2     3391\n",
       "3     1484\n",
       "4      641\n",
       "Name: mark, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.mark.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be critical for classifier to have such a large number of one class and a little number of other classes, so we remember it and may do oversampling later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can try different approaches: classification with 5 classes, or regression with target 'mark'.\n",
    "### Let`s try classification first:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before classification or regression we must extract features from the data, I`ll use **TfidfVectorizer** (because usually it is better than regular *bag-of-words*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.2 s, sys: 40 ms, total: 5.24 s\n",
      "Wall time: 5.36 s\n",
      "(28916, 134520)\n"
     ]
    }
   ],
   "source": [
    "X = data['sentiment']\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "\n",
    "%time X = vectorizer.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a data to train our models. Let`s try all the classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1). Linear models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data['mark']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01 \t accuracy=0.6105 +-0.0002\n",
      "C=0.1 \t accuracy=0.7511 +-0.0035\n",
      "C=0.5 \t accuracy=0.7799 +-0.0028\n",
      "C=1 \t accuracy=0.7844 +-0.0025\n",
      "C=5 \t accuracy=0.7832 +-0.0009\n",
      "C=10 \t accuracy=0.7791 +-0.0012\n",
      "C=100 \t accuracy=0.7643 +-0.0014\n",
      "C=200 \t accuracy=0.7612 +-0.0009\n",
      "C=500 \t accuracy=0.7572 +-0.0013\n",
      "C=1000 \t accuracy=0.7556 +-0.0015\n",
      "C=10000 \t accuracy=0.7504 +-0.0007\n",
      "C=15000 \t accuracy=0.7504 +-0.0010\n",
      "C=20000 \t accuracy=0.7501 +-0.0007\n",
      "C=100000 \t accuracy=0.7485 +-0.0021\n",
      "CPU times: user 10min 5s, sys: 547 ms, total: 10min 6s\n",
      "Wall time: 10min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_acc = -1\n",
    "best_C = -1\n",
    "for cur_C in [0.01, 0.1, 0.5, 1, 5, 10, 100, 200, 500, 1000, 10000, 15000, 20000, 100000]:\n",
    "    cls = LogisticRegression(C=cur_C)\n",
    "    cv_scores = cross_val_score(cls, X, y, scoring=\"accuracy\", cv=5)\n",
    "    cur_avg_acc = np.mean(cv_scores)\n",
    "    if cur_avg_acc > best_acc:\n",
    "        best_acc = cur_avg_acc\n",
    "        best_C = cur_C\n",
    "    print('C={0}'.format(cur_C), '\\t', \n",
    "          'accuracy={0:0.4f}'.format(cur_avg_acc), \n",
    "          '+-{0:0.4f}'.format(np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params are: C=1 with accuracy=0.7844\n"
     ]
    }
   ],
   "source": [
    "print('Best params are: C={0} with accuracy={1:0.4f}'.format(best_C, best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StochasticGradientDescentClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.0001, power_t=0.1 \t accuracy=0.7874 +-0.0024\n",
      "alpha=0.0001, power_t=0.5 \t accuracy=0.7871 +-0.0028\n",
      "alpha=0.0001, power_t=1 \t accuracy=0.7874 +-0.0023\n",
      "alpha=0.0001, power_t=1.5 \t accuracy=0.7875 +-0.0025\n",
      "alpha=0.0001, power_t=2 \t accuracy=0.7872 +-0.0031\n",
      "alpha=0.0001, power_t=3 \t accuracy=0.7871 +-0.0032\n",
      "alpha=0.0001, power_t=5 \t accuracy=0.7873 +-0.0027\n",
      "alpha=0.0001, power_t=10 \t accuracy=0.7871 +-0.0030\n",
      "alpha=0.0001, power_t=100 \t accuracy=0.7873 +-0.0025\n",
      "alpha=0.0001, power_t=500 \t accuracy=0.7875 +-0.0021\n",
      "alpha=0.0001, power_t=1000 \t accuracy=0.7870 +-0.0024\n",
      "alpha=0.0005, power_t=0.1 \t accuracy=0.7706 +-0.0033\n",
      "alpha=0.0005, power_t=0.5 \t accuracy=0.7703 +-0.0031\n",
      "alpha=0.0005, power_t=1 \t accuracy=0.7707 +-0.0034\n",
      "alpha=0.0005, power_t=1.5 \t accuracy=0.7708 +-0.0030\n",
      "alpha=0.0005, power_t=2 \t accuracy=0.7704 +-0.0028\n",
      "alpha=0.0005, power_t=3 \t accuracy=0.7711 +-0.0036\n",
      "alpha=0.0005, power_t=5 \t accuracy=0.7709 +-0.0032\n",
      "alpha=0.0005, power_t=10 \t accuracy=0.7703 +-0.0031\n",
      "alpha=0.0005, power_t=100 \t accuracy=0.7703 +-0.0027\n",
      "alpha=0.0005, power_t=500 \t accuracy=0.7716 +-0.0033\n",
      "alpha=0.0005, power_t=1000 \t accuracy=0.7704 +-0.0028\n",
      "alpha=0.001, power_t=0.1 \t accuracy=0.7512 +-0.0036\n",
      "alpha=0.001, power_t=0.5 \t accuracy=0.7513 +-0.0036\n",
      "alpha=0.001, power_t=1 \t accuracy=0.7508 +-0.0041\n",
      "alpha=0.001, power_t=1.5 \t accuracy=0.7508 +-0.0038\n",
      "alpha=0.001, power_t=2 \t accuracy=0.7509 +-0.0039\n",
      "alpha=0.001, power_t=3 \t accuracy=0.7509 +-0.0041\n",
      "alpha=0.001, power_t=5 \t accuracy=0.7508 +-0.0038\n",
      "alpha=0.001, power_t=10 \t accuracy=0.7510 +-0.0036\n",
      "alpha=0.001, power_t=100 \t accuracy=0.7509 +-0.0040\n",
      "alpha=0.001, power_t=500 \t accuracy=0.7509 +-0.0037\n",
      "alpha=0.001, power_t=1000 \t accuracy=0.7511 +-0.0041\n",
      "alpha=0.01, power_t=0.1 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.01, power_t=0.5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.01, power_t=1 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.01, power_t=1.5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.01, power_t=2 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.01, power_t=3 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.01, power_t=5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.01, power_t=10 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.01, power_t=100 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.01, power_t=500 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.01, power_t=1000 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.1, power_t=0.1 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.1, power_t=0.5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.1, power_t=1 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.1, power_t=1.5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.1, power_t=2 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.1, power_t=3 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.1, power_t=5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.1, power_t=10 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.1, power_t=100 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.1, power_t=500 \t accuracy=0.6104 +-0.0001\n",
      "alpha=0.1, power_t=1000 \t accuracy=0.6104 +-0.0001\n",
      "alpha=1, power_t=0.1 \t accuracy=0.6104 +-0.0001\n",
      "alpha=1, power_t=0.5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=1, power_t=1 \t accuracy=0.6104 +-0.0001\n",
      "alpha=1, power_t=1.5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=1, power_t=2 \t accuracy=0.6104 +-0.0001\n",
      "alpha=1, power_t=3 \t accuracy=0.6104 +-0.0001\n",
      "alpha=1, power_t=5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=1, power_t=10 \t accuracy=0.6104 +-0.0001\n",
      "alpha=1, power_t=100 \t accuracy=0.6104 +-0.0001\n",
      "alpha=1, power_t=500 \t accuracy=0.6104 +-0.0001\n",
      "alpha=1, power_t=1000 \t accuracy=0.6104 +-0.0001\n",
      "alpha=2, power_t=0.1 \t accuracy=0.6104 +-0.0001\n",
      "alpha=2, power_t=0.5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=2, power_t=1 \t accuracy=0.6104 +-0.0001\n",
      "alpha=2, power_t=1.5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=2, power_t=2 \t accuracy=0.6104 +-0.0001\n",
      "alpha=2, power_t=3 \t accuracy=0.6104 +-0.0001\n",
      "alpha=2, power_t=5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=2, power_t=10 \t accuracy=0.6104 +-0.0001\n",
      "alpha=2, power_t=100 \t accuracy=0.6104 +-0.0001\n",
      "alpha=2, power_t=500 \t accuracy=0.6104 +-0.0001\n",
      "alpha=2, power_t=1000 \t accuracy=0.6104 +-0.0001\n",
      "alpha=4, power_t=0.1 \t accuracy=0.6104 +-0.0001\n",
      "alpha=4, power_t=0.5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=4, power_t=1 \t accuracy=0.6104 +-0.0001\n",
      "alpha=4, power_t=1.5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=4, power_t=2 \t accuracy=0.6104 +-0.0001\n",
      "alpha=4, power_t=3 \t accuracy=0.6104 +-0.0001\n",
      "alpha=4, power_t=5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=4, power_t=10 \t accuracy=0.6104 +-0.0001\n",
      "alpha=4, power_t=100 \t accuracy=0.6104 +-0.0001\n",
      "alpha=4, power_t=500 \t accuracy=0.6104 +-0.0001\n",
      "alpha=4, power_t=1000 \t accuracy=0.6104 +-0.0001\n",
      "alpha=5, power_t=0.1 \t accuracy=0.6104 +-0.0001\n",
      "alpha=5, power_t=0.5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=5, power_t=1 \t accuracy=0.6104 +-0.0001\n",
      "alpha=5, power_t=1.5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=5, power_t=2 \t accuracy=0.6104 +-0.0001\n",
      "alpha=5, power_t=3 \t accuracy=0.6104 +-0.0001\n",
      "alpha=5, power_t=5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=5, power_t=10 \t accuracy=0.6104 +-0.0001\n",
      "alpha=5, power_t=100 \t accuracy=0.6104 +-0.0001\n",
      "alpha=5, power_t=500 \t accuracy=0.6104 +-0.0001\n",
      "alpha=5, power_t=1000 \t accuracy=0.6104 +-0.0001\n",
      "alpha=10, power_t=0.1 \t accuracy=0.5510 +-0.1188\n",
      "alpha=10, power_t=0.5 \t accuracy=0.6206 +-0.0202\n",
      "alpha=10, power_t=1 \t accuracy=0.6104 +-0.0001\n",
      "alpha=10, power_t=1.5 \t accuracy=0.6104 +-0.0001\n",
      "alpha=10, power_t=2 \t accuracy=0.6104 +-0.0001\n",
      "alpha=10, power_t=3 \t accuracy=0.6104 +-0.0001\n",
      "alpha=10, power_t=5 \t accuracy=0.6216 +-0.0137\n",
      "alpha=10, power_t=10 \t accuracy=0.6104 +-0.0001\n",
      "alpha=10, power_t=100 \t accuracy=0.6104 +-0.0001\n",
      "alpha=10, power_t=500 \t accuracy=0.6104 +-0.0001\n",
      "alpha=10, power_t=1000 \t accuracy=0.6104 +-0.0001\n",
      "CPU times: user 4min 9s, sys: 36.7 ms, total: 4min 9s\n",
      "Wall time: 4min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_acc = -1\n",
    "best_alpha = -1\n",
    "best_t = -1\n",
    "for cur_alpha, cur_t in itertools.product([0.0001, 0.0005, 0.001, 0.01, 0.1, 1, 2, 4, 5, 10],\n",
    "                                          [0.1, 0.5, 1, 1.5, 2, 3, 5, 10, 100, 500, 1000]):\n",
    "    cls = SGDClassifier(alpha=cur_alpha, power_t=cur_t)\n",
    "    cv_scores = cross_val_score(cls, X, y, scoring=\"accuracy\", cv=5)\n",
    "    cur_avg_acc = np.mean(cv_scores)\n",
    "    if cur_avg_acc > best_acc:\n",
    "        best_acc = cur_avg_acc\n",
    "        best_alpha = cur_alpha\n",
    "        best_t = cur_t\n",
    "    print('alpha={0}, power_t={1}'.format(cur_alpha, cur_t), '\\t', \n",
    "          'accuracy={0:0.4f}'.format(cur_avg_acc), \n",
    "          '+-{0:0.4f}'.format(np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params are: alpha=0.0001, power_t=1.5 with accuracy=0.7875\n"
     ]
    }
   ],
   "source": [
    "print('Best params are: alpha={0}, power_t={1} with accuracy={2:0.4f}'.format(best_alpha, best_t, best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PassiveAgressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01 \t accuracy=0.7700 +-0.0031\n",
      "C=0.1 \t accuracy=0.7895 +-0.0022\n",
      "C=0.5 \t accuracy=0.7674 +-0.0045\n",
      "C=1 \t accuracy=0.7556 +-0.0023\n",
      "C=5 \t accuracy=0.7489 +-0.0046\n",
      "C=10 \t accuracy=0.7454 +-0.0048\n",
      "C=100 \t accuracy=0.7472 +-0.0056\n",
      "C=200 \t accuracy=0.7441 +-0.0057\n",
      "C=500 \t accuracy=0.7500 +-0.0024\n",
      "C=1000 \t accuracy=0.7472 +-0.0033\n",
      "C=10000 \t accuracy=0.7444 +-0.0053\n",
      "C=15000 \t accuracy=0.7421 +-0.0043\n",
      "C=20000 \t accuracy=0.7454 +-0.0069\n",
      "C=100000 \t accuracy=0.7451 +-0.0066\n",
      "CPU times: user 31 s, sys: 0 ns, total: 31 s\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_acc = -1\n",
    "best_C = -1\n",
    "for cur_C in [0.01, 0.1, 0.5, 1, 5, 10, 100, 200, 500, 1000, 10000, 15000, 20000, 100000]:\n",
    "    cls = PassiveAggressiveClassifier(C=cur_C)\n",
    "    cv_scores = cross_val_score(cls, X, y, scoring=\"accuracy\", cv=5)\n",
    "    cur_avg_acc = np.mean(cv_scores)\n",
    "    if cur_avg_acc > best_acc:\n",
    "        best_acc = cur_avg_acc\n",
    "        best_C = cur_C\n",
    "    print('C={0}'.format(cur_C), '\\t', \n",
    "          'accuracy={0:0.4f}'.format(cur_avg_acc), \n",
    "          '+-{0:0.4f}'.format(np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params are: C=0.1 with accuracy=0.7895\n"
     ]
    }
   ],
   "source": [
    "print('Best params are: C={0} with accuracy={1:0.4f}'.format(best_C, best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.01 \t accuracy=0.7129 +-0.0064\n",
      "alpha=0.05 \t accuracy=0.7332 +-0.0061\n",
      "alpha=0.1 \t accuracy=0.7473 +-0.0040\n",
      "alpha=0.5 \t accuracy=0.7783 +-0.0016\n",
      "alpha=1 \t accuracy=0.7840 +-0.0017\n",
      "alpha=1.5 \t accuracy=0.7864 +-0.0029\n",
      "alpha=3 \t accuracy=0.7859 +-0.0026\n",
      "alpha=5 \t accuracy=0.7848 +-0.0025\n",
      "alpha=10 \t accuracy=0.7808 +-0.0027\n",
      "alpha=100 \t accuracy=0.7147 +-0.0034\n",
      "alpha=250 \t accuracy=0.6306 +-0.0011\n",
      "alpha=500 \t accuracy=0.6104 +-0.0001\n",
      "alpha=1000 \t accuracy=0.6104 +-0.0001\n",
      "CPU times: user 6min 22s, sys: 983 ms, total: 6min 23s\n",
      "Wall time: 6min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_acc = -1\n",
    "best_alpha = -1\n",
    "for cur_alpha in [0.01,0.05, 0.1, 0.5, 1, 1.5, 3, 5, 10, 100, 250, 500, 1000]:\n",
    "    cls = RidgeClassifier(alpha=cur_alpha)\n",
    "    cv_scores = cross_val_score(cls, X, y, scoring=\"accuracy\", cv=5)\n",
    "    cur_avg_acc = np.mean(cv_scores)\n",
    "    if cur_avg_acc > best_acc:\n",
    "        best_acc = cur_avg_acc\n",
    "        best_alpha = cur_alpha\n",
    "    print('alpha={0}'.format(cur_alpha), '\\t', \n",
    "          'accuracy={0:0.4f}'.format(cur_avg_acc), \n",
    "          '+-{0:0.4f}'.format(np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params are: alpha=1.5 with accuracy=0.7844\n"
     ]
    }
   ],
   "source": [
    "print('Best params are: alpha={0} with accuracy={1:0.4f}'.format(best_alpha, best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The winner among the linear models - PassiveAgressiveClassifier with accuracy=0.7895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3). Bayesian Classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "best_acc = -1\n",
    "best_alpha = -1\n",
    "for cur_alpha in np.arange(0.01, 500, 0.05):\n",
    "    cls = BernoulliNB(alpha=cur_alpha)\n",
    "    cv_scores = cross_val_score(cls, X, y, scoring=\"accuracy\", cv=5)\n",
    "    cur_avg_acc = np.mean(cv_scores)\n",
    "    if cur_avg_acc > best_acc:\n",
    "        best_acc = cur_avg_acc\n",
    "        best_alpha = cur_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Best params are: alpha={0} with accuracy={1:0.4f}'.format(best_alpha, best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3). Metric Classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "best_acc = -1\n",
    "best_k = -1\n",
    "for cur_k in range(50):\n",
    "    cls = KNeighborsClassifier(n_)\n",
    "    cv_scores = cross_val_score(cls, X, y, scoring=\"accuracy\", cv=5)\n",
    "    cur_avg_acc = np.mean(cv_scores)\n",
    "    if cur_avg_acc > best_acc:\n",
    "        best_acc = cur_avg_acc\n",
    "        best_alpha = cur_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4). Ensembles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomTreesEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748547663798\n",
      "CPU times: user 56.2 s, sys: 3.33 ms, total: 56.2 s\n",
      "Wall time: 56.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = AdaBoostClassifier()\n",
    "cv_scores = cross_val_score(cls, X, y, scoring=\"accuracy\", cv=5)\n",
    "print(cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748547663798\n",
      "CPU times: user 56.7 s, sys: 3.33 ms, total: 56.7 s\n",
      "Wall time: 56.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = BaggingClassifier()\n",
    "cv_scores = cross_val_score(cls, X, y, scoring=\"accuracy\", cv=5)\n",
    "print(cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748547663798\n",
      "CPU times: user 57.5 s, sys: 3.33 ms, total: 57.5 s\n",
      "Wall time: 57.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = ExtraTreesClassifier()\n",
    "cv_scores = cross_val_score(cls, X, y, scoring=\"accuracy\", cv=5)\n",
    "print(cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748547663798\n",
      "CPU times: user 58.9 s, sys: 3.33 ms, total: 58.9 s\n",
      "Wall time: 58.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier()\n",
    "cv_scores = cross_val_score(cls, X, y, scoring=\"accuracy\", cv=5)\n",
    "print(cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748547663798\n",
      "CPU times: user 57.7 s, sys: 0 ns, total: 57.7 s\n",
      "Wall time: 57.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomTreesEmbedding()\n",
    "cv_scores = cross_val_score(cls, X, y, scoring=\"accuracy\", cv=5)\n",
    "print(cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let`s turn to the main candidates - **gradient boosting classifiers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c88d1d157a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "- parameter tuning for ensembles\n",
    "- give it a try to reduce space dimension and try L1 feature_selection (http://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "- make the GridSearch for GradientBoostingClassifiers\n",
    "- try LDA for feature transformation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
