{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Respalizer (c). Data analysis (regression).\n",
    "## Made by Ilya Zakharkin (github.com/izaharkin)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural language processing (sentiment analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data: Given data - responses of people on different bank companies (two features - sentiment (text, in russian) and mark (integer, 1 <= mark <= 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: We must predict which mark will this person give consider his response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful materials:\n",
    "- scikit-learn example: http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#sphx-glr-auto-examples-text-document-classification-20newsgroups-py\n",
    "- article for beginners: https://habrahabr.ru/company/mlclass/blog/270591/\n",
    "- TJ texts classification: https://habrahabr.ru/post/327072/\n",
    "- MIPT NLP course: https://github.com/canorbal/NLP_MIPT/\n",
    "- Russian language processing research: http://corpus.leeds.ac.uk/mocky/\n",
    "- example with nltk: http://streamhacker.com/2012/11/22/text-classification-sentiment-analysis-nltk-scikitlearn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import joblib\n",
    "import _pickle\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/responses_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mark</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Я имею кредитную карту. Пользуюсь ею длительно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Всем привет! Я в этом банке , как только рухну...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Добрый вечер.Был вашим вкладчиком на протяжени...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Очень разочарована банком ВТБ24. За смс уведом...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Отвратительный банк, и обслуживание. 24.11.201...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mark                                        description\n",
       "0     5  Я имею кредитную карту. Пользуюсь ею длительно...\n",
       "1     5  Всем привет! Я в этом банке , как только рухну...\n",
       "2     1  Добрый вечер.Был вашим вкладчиком на протяжени...\n",
       "3     1  Очень разочарована банком ВТБ24. За смс уведом...\n",
       "4     1  Отвратительный банк, и обслуживание. 24.11.201..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_columns = data.columns.values\n",
    "new_columns[1] = 'sentiment'\n",
    "data.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fb9e8fc0668>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/matplotlib/font_manager.py:1297: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAFWCAYAAAB93nQWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n938Bc3Z59pQk6qAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb9ec94ca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.mark.value_counts().plot(kind='bar', label='mark', color='orange')\n",
    "plt.legend(fontsize=15)\n",
    "plt.title('Amount of each mark in the sample data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.43 s, sys: 0 ns, total: 5.43 s\n",
      "Wall time: 5.46 s\n",
      "(28916, 134520)\n"
     ]
    }
   ],
   "source": [
    "X = data['sentiment']\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "\n",
    "%time X = vectorizer.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data['mark']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1). Linear models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.linear_model import LassoLars, Lars\n",
    "\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model.huber import HuberRegressor \n",
    "from sklearn.linear_model import ARDRegression\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see who is **the best among linear models**.   \n",
    "Let's iterate over all this models and compare them. If we have root_mean_squared_error < 0.5, it will be good enough, because that means that average error of our model < 0.5, so when we will cast our prediction to the nearest integer number, it will be probably the right answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
      "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
      "       loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False) has rmse = 1.5539 +- 0.0567\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) has rmse = 0.9130 +- 0.0378\n",
      "\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001) has rmse = 0.8672 +- 0.0202\n",
      "\n",
      "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False) has rmse = 1.5917 +- 0.0476\n",
      "\n",
      "PassiveAggressiveRegressor(C=1.0, epsilon=0.1, fit_intercept=True,\n",
      "              loss='epsilon_insensitive', n_iter=5, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False) has rmse = 0.9643 +- 0.0201\n",
      "\n",
      "HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,\n",
      "        tol=1e-05, warm_start=False) has rmse = 0.9169 +- 0.0357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [SGDRegressor(), LogisticRegression(), Ridge(), ElasticNet(), TheilSenRegressor(),\n",
    "          Lars(), LassoLars(), PassiveAggressiveRegressor(), OrthogonalMatchingPursuit(),\n",
    "          HuberRegressor(), ARDRegression(), BayesianRidge()]\n",
    "\n",
    "best_score = -sys.float_info.max\n",
    "best_estimator = ''\n",
    "for model in models:\n",
    "    try:\n",
    "        cv_scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "        cv_mean_score = cv_scores.mean()\n",
    "        print('{0} has rmse = {1:.4f}+-{2:.4f}\\n'.format(str(model), np.sqrt(-cv_mean_score), cv_scores.std()))\n",
    "        if cv_mean_score > best_score:\n",
    "            best_score = cv_mean_score\n",
    "            best_estimator = str(model)\n",
    "    except:\n",
    "        continue  # because some of this models don`t support sparse matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best among linear models is Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001) with rmse = 0.8672\n"
     ]
    }
   ],
   "source": [
    "print('Best among linear models is {0} with rmse = {1:.4f}'.format(str(best_estimator), np.sqrt(-best_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2). Ensembles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False) has rmse = 0.9742 +- 0.0472\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False) has rmse = 0.9922 +- 0.0428\n"
     ]
    }
   ],
   "source": [
    "models = [ExtraTreesRegressor(), RandomForestRegressor()]\n",
    "# AdaBoostRegressor has rmse = 1.2715 +- 0.0964\n",
    "# BaggingRegressor(KNeighborsRegressor())\n",
    "best_score = -sys.float_info.max\n",
    "best_estimator = ''\n",
    "for model in models:\n",
    "    try:\n",
    "        cv_scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "        cv_mean_score = cv_scores.mean()\n",
    "        print('{0} has rmse = {1:.4f} +- {2:.4f}'.format(str(model), np.sqrt(-cv_mean_score), cv_scores.std()))\n",
    "        if cv_mean_score > best_score:\n",
    "            best_score = cv_mean_score\n",
    "            best_estimator = str(model)\n",
    "    except TypeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So, ensembles are less efficient, than linear models for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let`s try to vectorize data with **bigrams**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26 s, sys: 290 ms, total: 26.3 s\n",
      "Wall time: 26.3 s\n",
      "(28916, 2044247)\n"
     ]
    }
   ],
   "source": [
    "X = data['sentiment']\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True)\n",
    "\n",
    "%time X = vectorizer.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
      "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
      "       loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False) has rmse = 1.6804+-0.0752\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) has rmse = 1.0044+-0.0523\n",
      "\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001) has rmse = 0.8691+-0.0216\n",
      "\n",
      "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False) has rmse = 1.5917+-0.0476\n",
      "\n",
      "PassiveAggressiveRegressor(C=1.0, epsilon=0.1, fit_intercept=True,\n",
      "              loss='epsilon_insensitive', n_iter=5, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False) has rmse = 0.8516+-0.0204\n",
      "\n",
      "HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,\n",
      "        tol=1e-05, warm_start=False) has rmse = 0.8492+-0.0196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [SGDRegressor(), LogisticRegression(), Ridge(), ElasticNet(), TheilSenRegressor(),\n",
    "          Lars(), LassoLars(), PassiveAggressiveRegressor(), OrthogonalMatchingPursuit(),\n",
    "          HuberRegressor(), ARDRegression(), BayesianRidge()]\n",
    "\n",
    "best_score = -sys.float_info.max\n",
    "best_estimator = ''\n",
    "for model in models:\n",
    "    try:\n",
    "        cv_scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "        cv_mean_score = cv_scores.mean()\n",
    "        print('{0} has rmse = {1:.4f}+-{2:.4f}\\n'.format(str(model), np.sqrt(-cv_mean_score), cv_scores.std()))\n",
    "        if cv_mean_score > best_score:\n",
    "            best_score = cv_mean_score\n",
    "            best_estimator = str(model)\n",
    "    except:\n",
    "        continue  # because some of this models don`t support sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best among linear models, trained on the data with bigrams, is HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,\n",
      "        tol=1e-05, warm_start=False) with rmse = 0.8492\n"
     ]
    }
   ],
   "source": [
    "print('Best among linear models, trained on the data with bigrams, is {0} with rmse = {1:.4f}'\n",
    "      .format(str(best_estimator), np.sqrt(-best_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let`s try to vectorize data with **bigrams and trigrams**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.5 s, sys: 1.03 s, total: 57.5 s\n",
      "Wall time: 57.5 s\n",
      "(28916, 6025327)\n"
     ]
    }
   ],
   "source": [
    "X = data['sentiment']\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), sublinear_tf=True)\n",
    "\n",
    "%time X = vectorizer.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data['mark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
      "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
      "       loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False) has rmse = 1.7312+-0.0827\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) has rmse = 1.1243+-0.0551\n",
      "\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001) has rmse = 0.9072+-0.0233\n",
      "\n",
      "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False) has rmse = 1.5917+-0.0476\n",
      "\n",
      "PassiveAggressiveRegressor(C=1.0, epsilon=0.1, fit_intercept=True,\n",
      "              loss='epsilon_insensitive', n_iter=5, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False) has rmse = 0.8660+-0.0224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [SGDRegressor(), LogisticRegression(), Ridge(), ElasticNet(), TheilSenRegressor(),\n",
    "          Lars(), LassoLars(), PassiveAggressiveRegressor(), OrthogonalMatchingPursuit(),\n",
    "          HuberRegressor(), ARDRegression(), BayesianRidge()]\n",
    "\n",
    "best_score = -sys.float_info.max\n",
    "best_estimator = ''\n",
    "for model in models:\n",
    "    try:\n",
    "        cv_scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "        cv_mean_score = cv_scores.mean()\n",
    "        print('{0} has rmse = {1:.4f}+-{2:.4f}\\n'.format(str(model), np.sqrt(-cv_mean_score), cv_scores.std()))\n",
    "        if cv_mean_score > best_score:\n",
    "            best_score = cv_mean_score\n",
    "            best_estimator = str(model)\n",
    "    except:\n",
    "        continue  # because some of this models don`t support sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best among linear models, trained on the data with bigrams and trigrams, is PassiveAggressiveRegressor(C=1.0, epsilon=0.1, fit_intercept=True,\n",
      "              loss='epsilon_insensitive', n_iter=5, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False) with rmse = 0.8660\n"
     ]
    }
   ],
   "source": [
    "print('Best among linear models, trained on the data with bigrams and trigrams, is {0} with rmse = {1:.4f}'\n",
    "      .format(str(best_estimator), np.sqrt(-best_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
